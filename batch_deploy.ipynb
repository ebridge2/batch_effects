{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyppo.ksample import KSample\n",
    "from combat import combat\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import graspy as gp\n",
    "import numpy as np\n",
    "from dask.distributed import Client, progress\n",
    "import dask.dataframe as ddf\n",
    "from scipy.stats import zscore, rankdata\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub(fname):\n",
    "    stext = os.path.basename(fname).split('_')\n",
    "    return('{}_{}'.format(stext[1], stext[3]))\n",
    "\n",
    "def get_sub_pheno_dat(subid, scan, pheno_dat):\n",
    "    matches = pheno_dat.index[pheno_dat[\"SUBID\"] == int(subid)].tolist()\n",
    "    match = np.min(matches)\n",
    "    return(int(pheno_dat.iloc[match][\"SEX\"]))\n",
    "\n",
    "def apply_along_dataset(scs, dsets, fn):\n",
    "    scs_xfmd = np.zeros(scs.shape) \n",
    "    for dset in np.unique(dsets):\n",
    "        scs_xfmd[dsets == dset,:] = np.apply_along_axis(fn, 0, scs[dsets == dset,:])\n",
    "    return(scs_xfmd)\n",
    "\n",
    "def ptr(x):\n",
    "    #x_ch = copy.deepcopy(x)\n",
    "    nz = x[x != 0]\n",
    "    x_rank = rankdata(nz)*2/(len(nz) + 1)\n",
    "    x[x != 0] = x_rank\n",
    "    x = (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BNU1', 'HNU1']\n"
     ]
    }
   ],
   "source": [
    "basepath = '/data/'\n",
    "pheno_basepath = '/phenotypic/'\n",
    "datasets = os.listdir(basepath)\n",
    "datasets.remove(\"phenotypic\")\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_dict = {}\n",
    "pheno_dat = {}\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    try:\n",
    "        pheno_dat[dataset] = pd.read_csv('{}{}_phenotypic_data.csv'.format(pheno_basepath, dataset))\n",
    "        scan_dict = {}\n",
    "        sex_dict = []\n",
    "        dset_dir = os.path.join('{}{}/graphs/FSL_nff_nsc_gsr_des'.format(basepath, dataset), '*.ssv')\n",
    "        for f in glob.glob(dset_dir):\n",
    "            gr_dat = gp.utils.import_edgelist(f)\n",
    "            sub = get_sub(f)\n",
    "            scan_dict[sub] = gr_dat.flatten()\n",
    "            scansub = sub.split('_')\n",
    "            sex_dict.append(get_sub_pheno_dat(scansub[0], scansub[1], pheno_dat[dataset]))\n",
    "        fmri_dict[dataset] = {}\n",
    "        fmri_dict[dataset][\"scans\"] = np.vstack(list(scan_dict.values()))\n",
    "        fmri_dict[dataset][\"subs\"] = list(scan_dict.keys())\n",
    "        fmri_dict[dataset][\"sex\"] = sex_dict\n",
    "        fmri_dict[dataset][\"dataset\"] = [i + 1 for j in range(0, fmri_dict[dataset][\"scans\"].shape[0])]\n",
    "    except Exception as e:\n",
    "        print(\"Error in {} Dataset.\".format(dataset))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(row):\n",
    "    try:\n",
    "        ds1 = row[0]; ds2 = row[1]; xfm = row[2]\n",
    "        scans = np.vstack((fmri_dict[ds1][\"scans\"], fmri_dict[ds2][\"scans\"]))\n",
    "        scans = scans[:,~np.all(scans == 0, axis=0)]\n",
    "        sex = np.array(fmri_dict[ds1][\"sex\"] + fmri_dict[ds2][\"sex\"])\n",
    "        datasets = np.array([1 for i in range(0, fmri_dict[ds1][\"scans\"].shape[0])] + [2 for i in range(0, fmri_dict[ds2][\"scans\"].shape[0])])\n",
    "        if xfm == \"raw\":\n",
    "            scans = scans\n",
    "        elif xfm == \"zscore\":\n",
    "            scans = apply_along_dataset(scans, datasets, zscore)\n",
    "        elif xfm == \"ptr\":\n",
    "            scans = apply_along_dataset(scans, datasets, ptr)\n",
    "        elif xfm == \"combat\":\n",
    "            scans = np.array(combat(pd.DataFrame(scans.T), datasets, model=None, numerical_covariates=None)).T\n",
    "        eff_batch = KSample(\"DCorr\").test(scans[datasets == 1,:], scans[datasets == 2,:])\n",
    "        eff_sex = KSample(\"DCorr\").test(scans[sex == 1,:], scans[sex == 2,:])\n",
    "    except:\n",
    "        eff_batch = (None, None)\n",
    "        eff_sex = (None, None)\n",
    "    return (row[0], row[1], row[2], eff_batch[0], eff_batch[1], eff_sex[0], eff_sex[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/.virtualenvs/batch/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 34353 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:36971</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:34353/status' target='_blank'>http://127.0.0.1:34353/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>33.51 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:36971' processes=6 threads=6, memory=33.51 GB>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncores = 30\n",
    "client = Client(threads_per_worker=1, n_workers=ncores)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset1 Dataset2 Transform\n",
      "0     BNU1     HNU1       raw\n",
      "1     BNU1     HNU1       ptr\n",
      "2     BNU1     HNU1    zscore\n",
      "3     BNU1     HNU1    combat\n"
     ]
    }
   ],
   "source": [
    "exps = []\n",
    "datasets = list(fmri_dict.keys())\n",
    "for i, ds1 in enumerate(datasets):\n",
    "    for j in range(i+1, len(datasets)):\n",
    "        for xfm in [\"raw\", \"ptr\", \"zscore\", \"combat\"]:\n",
    "            exps.append([ds1, datasets[j], xfm])\n",
    "sim_exps = pd.DataFrame(exps, columns=[\"Dataset1\", \"Dataset2\", \"Transform\"])\n",
    "print(sim_exps.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_exps = ddf.from_pandas(sim_exps, npartitions=ncores)\n",
    "sim_results = sim_exps.apply(lambda x: run_experiment(x), axis=1, result_type='expand',\n",
    "                             meta={0: str, 1: str, 2: str, 3: float, 4: float, 5: float, 6: float})\n",
    "sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-745dca97b575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multiprocessing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msim_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;34m\"Effect.Batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pvalue.Batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Effect.Sex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pvalue.Sex\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sim_results' is not defined"
     ]
    }
   ],
   "source": [
    "sim_results = sim_results.compute(scheduler=\"multiprocessing\")\n",
    "sim_results = sim_results.rename(columns={0: \"Dataset1\", 1: \"Dataset2\", 2: \"Transform\", 3: \"Effect.Batch\",\n",
    "                                          4: \"pvalue.Batch\", 5: \"Effect.Sex\", 6: \"pvalue.Sex\"})\n",
    "sim_results.to_csv('./data/batch_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26217454597493484, 7.874182809594927e-25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "found 2 batches\n",
      "found 0 numerical covariates...\n",
      "found 0 categorical variables:\t\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors\n",
      "Finding parametric adjustments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting data\n"
     ]
    }
   ],
   "source": [
    "combat_scans = combat(pd.DataFrame(scans.T), datasets, model=None, numerical_covariates=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False]), slice(None, None, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-302e3f9cc117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meff_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DCorr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombat_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombat_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/batch/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/batch/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_index_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"get_indexer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/batch/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2644\u001b[0m                 )\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False]), slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "eff_batch = KSample(\"DCorr\").test(combat_scans[datasets == 1,:], combat_scans[datasets == 2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(array([False, False, False,  True, False,  True,  True, False, False,\n       False, False,  True, False, False,  True, False,  True, False,\n        True, False, False, False, False, False,  True,  True,  True,\n       False, False, False, False, False,  True, False,  True, False,\n       False, False, False,  True, False,  True, False,  True,  True,\n        True,  True,  True, False, False,  True, False,  True,  True,\n       False, False,  True,  True, False, False, False,  True, False,\n        True,  True,  True, False,  True,  True,  True,  True,  True,\n        True, False, False, False,  True,  True,  True, False,  True,\n        True,  True, False,  True, False,  True, False,  True,  True,\n        True, False, False, False, False,  True,  True, False,  True,\n       False, False,  True, False, False, False, False, False, False,\n       False,  True,  True,  True, False, False,  True, False, False,\n        True, False,  True,  True, False, False,  True, False,  True,\n        True,  True, False, False, False,  True,  True, False,  True,\n        True,  True, False, False,  True, False, False,  True, False,\n        True,  True, False,  True,  True,  True, False, False, False,\n        True, False, False, False, False,  True, False,  True, False,\n       False,  True, False,  True,  True, False, False, False,  True,\n       False, False, False, False, False, False,  True,  True,  True,\n       False,  True,  True,  True, False,  True,  True,  True,  True,\n        True, False, False, False, False, False, False, False, False,\n       False, False,  True,  True,  True, False, False, False,  True,\n       False,  True,  True, False, False,  True, False,  True, False,\n        True, False, False,  True,  True, False,  True, False,  True,\n       False, False,  True,  True, False,  True, False,  True, False,\n        True, False,  True,  True, False,  True, False,  True, False,\n        True, False,  True,  True,  True, False, False, False,  True,\n        True,  True,  True, False,  True,  True,  True,  True,  True,\n       False, False,  True, False,  True, False, False, False, False,\n       False, False, False,  True,  True,  True,  True,  True,  True,\n       False, False,  True, False,  True,  True,  True,  True, False,\n        True,  True, False,  True, False,  True,  True,  True, False,\n        True,  True, False,  True, False,  True,  True, False,  True,\n       False,  True, False,  True, False, False, False, False,  True,\n       False,  True, False,  True,  True, False, False,  True,  True,\n       False, False,  True,  True,  True,  True, False,  True,  True,\n       False, False,  True,  True, False, False,  True, False,  True,\n       False,  True,  True,  True, False,  True, False,  True, False,\n        True,  True,  True, False,  True,  True, False,  True, False,\n       False, False,  True,  True, False,  True,  True, False, False,\n        True,  True,  True,  True, False,  True, False, False,  True,\n       False, False, False,  True, False, False, False,  True, False,\n        True, False, False,  True,  True, False,  True,  True, False,\n       False, False,  True,  True]), slice(None, None, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-76584cb6f20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meff_sex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DCorr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombat_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombat_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/batch/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/batch/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_index_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"get_indexer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/batch/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2644\u001b[0m                 )\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(array([False, False, False,  True, False,  True,  True, False, False,\n       False, False,  True, False, False,  True, False,  True, False,\n        True, False, False, False, False, False,  True,  True,  True,\n       False, False, False, False, False,  True, False,  True, False,\n       False, False, False,  True, False,  True, False,  True,  True,\n        True,  True,  True, False, False,  True, False,  True,  True,\n       False, False,  True,  True, False, False, False,  True, False,\n        True,  True,  True, False,  True,  True,  True,  True,  True,\n        True, False, False, False,  True,  True,  True, False,  True,\n        True,  True, False,  True, False,  True, False,  True,  True,\n        True, False, False, False, False,  True,  True, False,  True,\n       False, False,  True, False, False, False, False, False, False,\n       False,  True,  True,  True, False, False,  True, False, False,\n        True, False,  True,  True, False, False,  True, False,  True,\n        True,  True, False, False, False,  True,  True, False,  True,\n        True,  True, False, False,  True, False, False,  True, False,\n        True,  True, False,  True,  True,  True, False, False, False,\n        True, False, False, False, False,  True, False,  True, False,\n       False,  True, False,  True,  True, False, False, False,  True,\n       False, False, False, False, False, False,  True,  True,  True,\n       False,  True,  True,  True, False,  True,  True,  True,  True,\n        True, False, False, False, False, False, False, False, False,\n       False, False,  True,  True,  True, False, False, False,  True,\n       False,  True,  True, False, False,  True, False,  True, False,\n        True, False, False,  True,  True, False,  True, False,  True,\n       False, False,  True,  True, False,  True, False,  True, False,\n        True, False,  True,  True, False,  True, False,  True, False,\n        True, False,  True,  True,  True, False, False, False,  True,\n        True,  True,  True, False,  True,  True,  True,  True,  True,\n       False, False,  True, False,  True, False, False, False, False,\n       False, False, False,  True,  True,  True,  True,  True,  True,\n       False, False,  True, False,  True,  True,  True,  True, False,\n        True,  True, False,  True, False,  True,  True,  True, False,\n        True,  True, False,  True, False,  True,  True, False,  True,\n       False,  True, False,  True, False, False, False, False,  True,\n       False,  True, False,  True,  True, False, False,  True,  True,\n       False, False,  True,  True,  True,  True, False,  True,  True,\n       False, False,  True,  True, False, False,  True, False,  True,\n       False,  True,  True,  True, False,  True, False,  True, False,\n        True,  True,  True, False,  True,  True, False,  True, False,\n       False, False,  True,  True, False,  True,  True, False, False,\n        True,  True,  True,  True, False,  True, False, False,  True,\n       False, False, False,  True, False, False, False,  True, False,\n        True, False, False,  True,  True, False,  True,  True, False,\n       False, False,  True,  True]), slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "eff_sex = KSample(\"DCorr\").test(combat_scans[sex == 1,:], combat_scans[sex == 2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eff_sex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e3dc98e63cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meff_sex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eff_sex' is not defined"
     ]
    }
   ],
   "source": [
    "eff_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079961</td>\n",
       "      <td>0.169019</td>\n",
       "      <td>0.013939</td>\n",
       "      <td>0.075546</td>\n",
       "      <td>0.324519</td>\n",
       "      <td>0.066174</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>0.173839</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.138987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026226</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>0.012179</td>\n",
       "      <td>0.163396</td>\n",
       "      <td>0.162671</td>\n",
       "      <td>0.170088</td>\n",
       "      <td>0.141930</td>\n",
       "      <td>0.364129</td>\n",
       "      <td>0.032054</td>\n",
       "      <td>0.260242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136965</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>0.068595</td>\n",
       "      <td>0.092722</td>\n",
       "      <td>0.471526</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.182966</td>\n",
       "      <td>0.067399</td>\n",
       "      <td>0.201577</td>\n",
       "      <td>0.040022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067657</td>\n",
       "      <td>0.358156</td>\n",
       "      <td>0.301873</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>0.259114</td>\n",
       "      <td>0.020551</td>\n",
       "      <td>0.250263</td>\n",
       "      <td>0.030788</td>\n",
       "      <td>0.374616</td>\n",
       "      <td>0.017455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017515</td>\n",
       "      <td>0.174713</td>\n",
       "      <td>0.117976</td>\n",
       "      <td>0.201546</td>\n",
       "      <td>0.455948</td>\n",
       "      <td>0.258870</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>0.256086</td>\n",
       "      <td>0.036762</td>\n",
       "      <td>0.208059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196671</td>\n",
       "      <td>0.402563</td>\n",
       "      <td>0.194152</td>\n",
       "      <td>0.284823</td>\n",
       "      <td>0.378998</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.315422</td>\n",
       "      <td>0.385325</td>\n",
       "      <td>0.016784</td>\n",
       "      <td>0.383083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.149464</td>\n",
       "      <td>0.226378</td>\n",
       "      <td>0.040478</td>\n",
       "      <td>0.104469</td>\n",
       "      <td>0.385379</td>\n",
       "      <td>0.033653</td>\n",
       "      <td>0.089574</td>\n",
       "      <td>0.173290</td>\n",
       "      <td>0.236768</td>\n",
       "      <td>0.077180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103193</td>\n",
       "      <td>0.201414</td>\n",
       "      <td>0.212215</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>0.224856</td>\n",
       "      <td>0.048098</td>\n",
       "      <td>0.208125</td>\n",
       "      <td>0.252847</td>\n",
       "      <td>0.229207</td>\n",
       "      <td>0.019543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.035035</td>\n",
       "      <td>0.142592</td>\n",
       "      <td>0.324699</td>\n",
       "      <td>0.102383</td>\n",
       "      <td>0.108207</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.039923</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>0.062477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057409</td>\n",
       "      <td>0.138324</td>\n",
       "      <td>0.156167</td>\n",
       "      <td>0.059341</td>\n",
       "      <td>0.244549</td>\n",
       "      <td>0.134895</td>\n",
       "      <td>0.147321</td>\n",
       "      <td>0.256275</td>\n",
       "      <td>0.241786</td>\n",
       "      <td>0.074325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>0.043034</td>\n",
       "      <td>0.107710</td>\n",
       "      <td>0.079939</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.228633</td>\n",
       "      <td>0.314604</td>\n",
       "      <td>0.183382</td>\n",
       "      <td>0.042760</td>\n",
       "      <td>0.163151</td>\n",
       "      <td>0.205678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>0.162969</td>\n",
       "      <td>0.164098</td>\n",
       "      <td>0.243588</td>\n",
       "      <td>0.275008</td>\n",
       "      <td>0.128743</td>\n",
       "      <td>0.166689</td>\n",
       "      <td>0.152616</td>\n",
       "      <td>0.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>0.188554</td>\n",
       "      <td>0.037594</td>\n",
       "      <td>0.218519</td>\n",
       "      <td>0.310148</td>\n",
       "      <td>0.224841</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.245050</td>\n",
       "      <td>0.104442</td>\n",
       "      <td>0.200475</td>\n",
       "      <td>0.211149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>0.056020</td>\n",
       "      <td>0.067998</td>\n",
       "      <td>0.208495</td>\n",
       "      <td>0.184677</td>\n",
       "      <td>0.021908</td>\n",
       "      <td>0.078296</td>\n",
       "      <td>0.200886</td>\n",
       "      <td>0.292110</td>\n",
       "      <td>0.092889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>0.040945</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.093545</td>\n",
       "      <td>0.167038</td>\n",
       "      <td>0.037455</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>0.151532</td>\n",
       "      <td>0.173338</td>\n",
       "      <td>0.199138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068557</td>\n",
       "      <td>0.255053</td>\n",
       "      <td>0.139579</td>\n",
       "      <td>0.199687</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.062191</td>\n",
       "      <td>0.092607</td>\n",
       "      <td>0.258694</td>\n",
       "      <td>0.029665</td>\n",
       "      <td>0.025783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>0.358038</td>\n",
       "      <td>0.401410</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>0.208878</td>\n",
       "      <td>0.389438</td>\n",
       "      <td>0.402954</td>\n",
       "      <td>0.256473</td>\n",
       "      <td>0.398740</td>\n",
       "      <td>0.259403</td>\n",
       "      <td>0.187288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107166</td>\n",
       "      <td>0.335564</td>\n",
       "      <td>0.130142</td>\n",
       "      <td>0.344607</td>\n",
       "      <td>0.179272</td>\n",
       "      <td>0.445320</td>\n",
       "      <td>0.330615</td>\n",
       "      <td>0.357884</td>\n",
       "      <td>0.242037</td>\n",
       "      <td>0.104853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>0.311512</td>\n",
       "      <td>0.183436</td>\n",
       "      <td>0.111484</td>\n",
       "      <td>0.301343</td>\n",
       "      <td>0.481925</td>\n",
       "      <td>0.164126</td>\n",
       "      <td>0.443613</td>\n",
       "      <td>0.325414</td>\n",
       "      <td>0.315284</td>\n",
       "      <td>0.236211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179532</td>\n",
       "      <td>0.152249</td>\n",
       "      <td>0.359219</td>\n",
       "      <td>0.302635</td>\n",
       "      <td>0.476924</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.238094</td>\n",
       "      <td>0.274213</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.048121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4830 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.079961  0.169019  0.013939  0.075546  0.324519  0.066174  0.130587   \n",
       "1     0.136965  0.027485  0.068595  0.092722  0.471526  0.045892  0.182966   \n",
       "2     0.017515  0.174713  0.117976  0.201546  0.455948  0.258870  0.026215   \n",
       "3     0.149464  0.226378  0.040478  0.104469  0.385379  0.033653  0.089574   \n",
       "4     0.051282  0.035035  0.142592  0.324699  0.102383  0.108207  0.029470   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4825  0.043034  0.107710  0.079939  0.012422  0.228633  0.314604  0.183382   \n",
       "4826  0.188554  0.037594  0.218519  0.310148  0.224841  0.019094  0.245050   \n",
       "4827  0.040945  0.012145  0.093545  0.167038  0.037455  0.383224  0.020973   \n",
       "4828  0.358038  0.401410  0.033422  0.208878  0.389438  0.402954  0.256473   \n",
       "4829  0.311512  0.183436  0.111484  0.301343  0.481925  0.164126  0.443613   \n",
       "\n",
       "           7         8         9    ...       390       391       392  \\\n",
       "0     0.173839  0.027809  0.138987  ...  0.026226  0.295544  0.012179   \n",
       "1     0.067399  0.201577  0.040022  ...  0.067657  0.358156  0.301873   \n",
       "2     0.256086  0.036762  0.208059  ...  0.196671  0.402563  0.194152   \n",
       "3     0.173290  0.236768  0.077180  ...  0.103193  0.201414  0.212215   \n",
       "4     0.039923  0.037383  0.062477  ...  0.057409  0.138324  0.156167   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4825  0.042760  0.163151  0.205678  ...  0.023906  0.018651  0.162969   \n",
       "4826  0.104442  0.200475  0.211149  ...  0.090584  0.056020  0.067998   \n",
       "4827  0.151532  0.173338  0.199138  ...  0.068557  0.255053  0.139579   \n",
       "4828  0.398740  0.259403  0.187288  ...  0.107166  0.335564  0.130142   \n",
       "4829  0.325414  0.315284  0.236211  ...  0.179532  0.152249  0.359219   \n",
       "\n",
       "           393       394       395       396       397       398       399  \n",
       "0     0.163396  0.162671  0.170088  0.141930  0.364129  0.032054  0.260242  \n",
       "1     0.012701  0.259114  0.020551  0.250263  0.030788  0.374616  0.017455  \n",
       "2     0.284823  0.378998  0.048994  0.315422  0.385325  0.016784  0.383083  \n",
       "3     0.021843  0.224856  0.048098  0.208125  0.252847  0.229207  0.019543  \n",
       "4     0.059341  0.244549  0.134895  0.147321  0.256275  0.241786  0.074325  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4825  0.164098  0.243588  0.275008  0.128743  0.166689  0.152616  0.084700  \n",
       "4826  0.208495  0.184677  0.021908  0.078296  0.200886  0.292110  0.092889  \n",
       "4827  0.199687  0.009020  0.062191  0.092607  0.258694  0.029665  0.025783  \n",
       "4828  0.344607  0.179272  0.445320  0.330615  0.357884  0.242037  0.104853  \n",
       "4829  0.302635  0.476924  0.011490  0.238094  0.274213  0.400600  0.048121  \n",
       "\n",
       "[4830 rows x 400 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combat_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batch",
   "language": "python",
   "name": "batch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
