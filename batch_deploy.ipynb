{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyppo.ksample import KSample\n",
    "from hyppo.independence import Dcorr\n",
    "from combat import combat\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import graspy as gp\n",
    "import numpy as np\n",
    "from dask.distributed import Client, progress\n",
    "import dask.dataframe as ddf\n",
    "from scipy.stats import zscore, rankdata, mannwhitneyu\n",
    "import copy\n",
    "import math\n",
    "import networkx as nx\n",
    "from graspy.models import SIEMEstimator as siem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub(fname):\n",
    "    stext = os.path.basename(fname).split('_')\n",
    "    return('{}_{}_{}'.format(stext[0], stext[1], stext[3]))\n",
    "\n",
    "def get_sub_pheno_dat(subid, scan, pheno_dat):\n",
    "    matches = pheno_dat.index[pheno_dat[\"SUBID\"] == int(subid)].tolist()\n",
    "    match = np.min(matches)\n",
    "    return(int(pheno_dat.iloc[match][\"SEX\"]))\n",
    "\n",
    "def get_age_pheno_dat(subid, scan, pheno_dat):\n",
    "    matches = pheno_dat.index[pheno_dat[\"SUBID\"] == int(subid)].tolist()\n",
    "    match = np.min(matches)\n",
    "    return(int(pheno_dat.iloc[match][\"AGE_AT_SCAN_1\"]))\n",
    "\n",
    "def apply_along_dataset(scs, dsets, fn):\n",
    "    scs_xfmd = np.zeros(scs.shape)\n",
    "    for dset in np.unique(dsets):\n",
    "        scs_xfmd[dsets == dset,:] = np.apply_along_axis(fn, 0, scs[dsets == dset,:])\n",
    "    return(scs_xfmd)\n",
    "\n",
    "def apply_along_individual(scs, fn):\n",
    "    scs_xfmd = np.zeros(scs.shape)\n",
    "\n",
    "def ptr(x):\n",
    "    x_ch = copy.deepcopy(x)\n",
    "    nz = x[x != 0]\n",
    "    x_rank = rankdata(nz)*2/(len(nz) + 1)\n",
    "    x_ch[x_ch != 0] = x_rank\n",
    "    if (np.min(x_ch) != np.max(x_ch)):\n",
    "        x_ch = (x_ch - np.min(x_ch))/(np.max(x_ch) - np.min(x_ch))\n",
    "    return(x_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/data/corr/'\n",
    "pheno_basepath = '/data/corr/phenotypic/'\n",
    "datasets = os.listdir(basepath)\n",
    "datasets.remove(\"phenotypic\")\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_dict = {}\n",
    "pheno_dat = {}\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    try:\n",
    "        pheno_dat[dataset] = pd.read_csv('{}{}_phenotypic_data.csv'.format(pheno_basepath, dataset))\n",
    "        scan_dict = {}\n",
    "        sex_dict = []\n",
    "        age_dict = []\n",
    "        dset_dir = os.path.join('{}{}/graphs/FSL_nff_nsc_gsr_des'.format(basepath, dataset), '*.ssv')\n",
    "        for f in glob.glob(dset_dir):\n",
    "            gr_dat = gp.utils.import_edgelist(f)\n",
    "            sub = get_sub(f)\n",
    "            scan_dict[sub] = gr_dat.flatten()\n",
    "            scansub = sub.split('_')\n",
    "            sex_dict.append(get_sub_pheno_dat(scansub[1], scansub[2], pheno_dat[dataset]))\n",
    "            age_dict.append(get_age_pheno_dat(scansub[1], scansub[2], pheno_dat[dataset]))\n",
    "        fmri_dict[dataset] = {}\n",
    "        fmri_dict[dataset][\"scans\"] = np.vstack(list(scan_dict.values()))\n",
    "        fmri_dict[dataset][\"subs\"] = list(scan_dict.keys())\n",
    "        fmri_dict[dataset][\"sex\"] = sex_dict\n",
    "        fmri_dict[dataset][\"age\"] = age_dict\n",
    "        fmri_dict[dataset][\"dataset\"] = [i + 1 for j in range(0, fmri_dict[dataset][\"scans\"].shape[0])]\n",
    "    except Exception as e:\n",
    "        print(\"Error in {} Dataset.\".format(dataset))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(row):\n",
    "    try:\n",
    "        ds1 = row[0]; ds2 = row[1]; sxfm=row[2]; dxfm = row[3]\n",
    "        scans = np.vstack((fmri_dict[ds1][\"scans\"], fmri_dict[ds2][\"scans\"]))\n",
    "        scans = scans[:,~np.all(scans == 0, axis=0)]\n",
    "        sex = np.array(fmri_dict[ds1][\"sex\"] + fmri_dict[ds2][\"sex\"])\n",
    "        age = np.array(fmri_dict[ds1][\"age\"] + fmri_dict[ds2][\"age\"])\n",
    "        datasets = np.array([1 for i in range(0, fmri_dict[ds1][\"scans\"].shape[0])] + [2 for i in range(0, fmri_dict[ds2][\"scans\"].shape[0])])\n",
    "        if sxfm == \"ptr\":\n",
    "            scans = np.apply_along_axis(ptr, 1, scans)\n",
    "        if dxfm == \"raw\":\n",
    "            scans = scans\n",
    "        elif dxfm == \"zscore\":\n",
    "            scans = apply_along_dataset(scans, datasets, zscore)\n",
    "        elif dxfm == \"ptr\":\n",
    "            scans = apply_along_dataset(scans, datasets, ptr)\n",
    "        elif dxfm == \"combat\":\n",
    "            scans = np.array(combat(pd.DataFrame(scans.T), datasets, model=None, numerical_covariates=None)).T\n",
    "        try:\n",
    "            eff_batch = KSample(\"DCorr\").test(scans[datasets == 1,:], scans[datasets == 2,:])\n",
    "        except:\n",
    "            eff_batch = (None, None)\n",
    "        try:\n",
    "            eff_sex = KSample(\"DCorr\").test(scans[sex == 1,:], scans[sex == 2,:])\n",
    "        except:\n",
    "            eff_sex = (None, None)\n",
    "        try:\n",
    "            eff_age = DCorr().test(scans, age)\n",
    "        except:\n",
    "            eff_age = (None, None)\n",
    "    except:\n",
    "        eff_batch = (None, None)\n",
    "        eff_sex = (None, None)\n",
    "        eff_age = (None, None)\n",
    "    return (row[0], row[1], row[2], eff_batch[0], eff_batch[1], eff_sex[0], eff_sex[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "## Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/.virtualenvs/batch/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 40809 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:44643</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:40809/status' target='_blank'>http://127.0.0.1:40809/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>33.51 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:44643' processes=6 threads=6, memory=33.51 GB>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncores = 6\n",
    "client = Client(threads_per_worker=1, n_workers=ncores)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = []\n",
    "datasets = list(fmri_dict.keys())\n",
    "for sxfm in [\"raw\", \"ptr\"]:\n",
    "    for i, ds1 in enumerate(datasets):\n",
    "        for j in range(i+1, len(datasets)):\n",
    "            for dxfm in [\"raw\", \"ptr\", \"zscore\", \"combat\"]:\n",
    "                exps.append([ds1, datasets[j], sxfm, dxfm])\n",
    "sim_exps = pd.DataFrame(exps, columns=[\"Dataset1\", \"Dataset2\", \"Sxfm\", \"Dxfm\"])\n",
    "print(sim_exps.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_exps = ddf.from_pandas(sim_exps, npartitions=ncores)\n",
    "sim_results = sim_exps.apply(lambda x: run_experiment(x), axis=1, result_type='expand',\n",
    "                             meta={0: str, 1: str, 2: str, 3: float, 4: float, 5: float, 6: float})\n",
    "sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results = sim_results.compute(scheduler=\"multiprocessing\")\n",
    "sim_results = sim_results.rename(columns={0: \"Dataset1\", 1: \"Dataset2\", 2: \"Transform\", 3: \"Effect.Batch\",\n",
    "                                          4: \"pvalue.Batch\", 5: \"Effect.Sex\", 6: \"pvalue.Sex\"})\n",
    "sim_results.to_csv('./data/batch_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preservation of Network Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_edges(n):\n",
    "    \"\"\"\n",
    "    A function for generating diagonal SIEM edge communities.\n",
    "    \"\"\"\n",
    "    m = int(n/2)\n",
    "    edge_comm = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if (i == j + m) or (j == i + m):\n",
    "                edge_comm[i,j] = 1\n",
    "            else:\n",
    "                edge_comm[i,j] = 2\n",
    "    return edge_comm\n",
    "\n",
    "des_diag = diag_edges(70)\n",
    "\n",
    "def modular_edges(n):\n",
    "    \"\"\"\n",
    "    A function for generating modular sbm edge communities.\n",
    "    \"\"\"\n",
    "    m = int(n/2)\n",
    "    edge_comm = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if ( (i<m) & (j<m)) or ( (i>=m ) & (j>=m) ):\n",
    "                edge_comm[i,j] = 1\n",
    "            else:\n",
    "                edge_comm[i,j] = 2   \n",
    "    return edge_comm\n",
    "\n",
    "des_modular = modular_edges(70)\n",
    "\n",
    "def mww(G, C):\n",
    "    A = G[C == 1]\n",
    "    B = G[C == 2]\n",
    "    return(mannwhitneyu(A, B, alternative='greater')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "found 2 batches\n",
      "found 0 numerical covariates...\n",
      "found 0 categorical variables:\t\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors\n",
      "Finding parametric adjustments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "found 2 batches\n",
      "found 0 numerical covariates...\n",
      "found 0 categorical variables:\t\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors\n",
      "Finding parametric adjustments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting data\n"
     ]
    }
   ],
   "source": [
    "dset_ls = [fmri_dict[ds][\"scans\"] for ds in fmri_dict.keys()]\n",
    "raw_dat = np.vstack(dset_ls)\n",
    "datasets = np.array([j for ds in fmri_dict.keys() for j in fmri_dict[ds][\"dataset\"]])\n",
    "# get the subject ids and dataset ids as a big list\n",
    "subjects = np.array([j for ds in fmri_dict.keys() for j in fmri_dict[ds][\"subs\"]])\n",
    "\n",
    "def prepare_aggregate_data(scans, datasets):\n",
    "    newdat = {}\n",
    "    newdat[\"raw\"] = copy.deepcopy(scans)\n",
    "    # copy the raw data over\n",
    "    newdat[\"zscore\"] = copy.deepcopy(scans)\n",
    "    newdat[\"ptr\"] = copy.deepcopy(scans)\n",
    "    newdat[\"combat\"] = copy.deepcopy(scans)\n",
    "\n",
    "    # remove stationary edges for combat\n",
    "    combat_rem_edges = ~np.all(newdat[\"combat\"] == 0, axis=0)\n",
    "\n",
    "    # apply relevant transforms en-masse\n",
    "    newdat[\"zscore\"] = apply_along_dataset(newdat[\"zscore\"], datasets, zscore)\n",
    "    # replace nans with zeros\n",
    "    newdat[\"zscore\"][np.isnan(newdat[\"zscore\"])] = 0\n",
    "    newdat[\"ptr\"] = apply_along_dataset(newdat[\"ptr\"], datasets, ptr)\n",
    "    newdat[\"combat\"][:,combat_rem_edges] = np.array(combat(pd.DataFrame(newdat[\"combat\"][:,combat_rem_edges].T), datasets, model=None, numerical_covariates=None)).T\n",
    "    return(newdat)\n",
    "\n",
    "data_preproc = {}\n",
    "data_preproc[\"raw\"] = prepare_aggregate_data(raw_dat, datasets)\n",
    "data_preproc[\"ptr\"] = prepare_aggregate_data(np.apply_along_axis(ptr, 1, raw_dat), datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset  Subject Retest  Ix        Fullname Sxfm    Dxfm\n",
      "0    BNU1  0025880      2   0  BNU1_0025880_2  raw     raw\n",
      "1    BNU1  0025880      2   0  BNU1_0025880_2  raw  zscore\n",
      "2    BNU1  0025880      2   0  BNU1_0025880_2  raw     ptr\n",
      "3    BNU1  0025880      2   0  BNU1_0025880_2  raw  combat\n",
      "4    BNU1  0025880      2   0  BNU1_0025880_2  ptr     raw\n"
     ]
    }
   ],
   "source": [
    "exps = []\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "    sspl = sub.split('_')\n",
    "    dset = sspl[0]\n",
    "    for sxfm in [\"raw\", \"ptr\"]:\n",
    "        for dxfm in [\"raw\", \"zscore\", \"ptr\", \"combat\"]:\n",
    "            exps.append([dset, sspl[1], sspl[2], i, sub, sxfm, dxfm])\n",
    "sim_exps = pd.DataFrame(exps, columns=[\"Dataset\", \"Subject\", \"Retest\", \"Ix\", \"Fullname\", \"Sxfm\", \"Dxfm\"])\n",
    "print(sim_exps.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singlegraph_exp(row):\n",
    "    # grab data, and reshape it to nv x nv matrix\n",
    "    flat_gr = data_preproc[row[5]][row[6]][subjects == row[4]][0,:]\n",
    "    nv = int(np.sqrt(np.max(flat_gr.shape)))\n",
    "    exp_gr = flat_gr.reshape((nv, nv))\n",
    "    G = nx.from_numpy_matrix(exp_gr)\n",
    "    cc = nx.average_clustering(G, weight=\"weight\")\n",
    "    deg = np.array(list(dict(G.degree(weight=\"weight\")).values())).mean()\n",
    "    homophil_stat = mww(exp_gr, des_modular)\n",
    "    homotop_stat = mww(exp_gr, des_diag)\n",
    "    return(row[0], row[1], row[2], row[3], row[4], row[5], row[6], cc, deg, homophil_stat, homotop_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=6</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: apply, 12 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   0       1       2       3       4       5       6        7        8        9        10\n",
       "npartitions=6                                                                                            \n",
       "0              object  object  object  object  object  object  object  float64  float64  float64  float64\n",
       "534               ...     ...     ...     ...     ...     ...     ...      ...      ...      ...      ...\n",
       "...               ...     ...     ...     ...     ...     ...     ...      ...      ...      ...      ...\n",
       "2670              ...     ...     ...     ...     ...     ...     ...      ...      ...      ...      ...\n",
       "3199              ...     ...     ...     ...     ...     ...     ...      ...      ...      ...      ...\n",
       "Dask Name: apply, 12 tasks"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_exps = ddf.from_pandas(sim_exps, npartitions=ncores)\n",
    "sim_results = sim_exps.apply(lambda x: singlegraph_exp(x), axis=1, result_type='expand',\n",
    "                             meta={0: str, 1: str, 2: str, 3:str, 4:str, 5:str, 6:str,\n",
    "                                   7: float, 8: float, 9: float, 10: float})\n",
    "sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results = sim_results.compute(scheduler=\"multiprocessing\")\n",
    "sim_results = sim_results.rename(columns={0: \"Dataset\", 1: \"Subject\", 2: \"Retest\", 3: \"Ix\",\n",
    "                                          4: \"Fullname\", 5: \"Sxfm\", 6: \"Dxfm\", 7: \"Clustering\",\n",
    "                                          8: \"Degree\", 9: \"Homophilic\", 10: \"Homotopic\"})\n",
    "sim_results.to_csv('./data/batch_statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Retest</th>\n",
       "      <th>Ix</th>\n",
       "      <th>Fullname</th>\n",
       "      <th>Sxfm</th>\n",
       "      <th>Dxfm</th>\n",
       "      <th>Clustering</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Homophilic</th>\n",
       "      <th>Homotopic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNU1</td>\n",
       "      <td>0025880</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>BNU1_0025880_2</td>\n",
       "      <td>raw</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.175662+0.000000j</td>\n",
       "      <td>12.861285</td>\n",
       "      <td>0.874698</td>\n",
       "      <td>0.926181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BNU1</td>\n",
       "      <td>0025880</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>BNU1_0025880_2</td>\n",
       "      <td>raw</td>\n",
       "      <td>zscore</td>\n",
       "      <td>0.127331+0.063867j</td>\n",
       "      <td>0.202158</td>\n",
       "      <td>0.388454</td>\n",
       "      <td>0.803617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BNU1</td>\n",
       "      <td>0025880</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>BNU1_0025880_2</td>\n",
       "      <td>raw</td>\n",
       "      <td>ptr</td>\n",
       "      <td>0.427748+0.000000j</td>\n",
       "      <td>34.424098</td>\n",
       "      <td>0.950291</td>\n",
       "      <td>0.645351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BNU1</td>\n",
       "      <td>0025880</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>BNU1_0025880_2</td>\n",
       "      <td>raw</td>\n",
       "      <td>combat</td>\n",
       "      <td>0.179922+0.001882j</td>\n",
       "      <td>13.343396</td>\n",
       "      <td>0.892313</td>\n",
       "      <td>0.943219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNU1</td>\n",
       "      <td>0025880</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>BNU1_0025880_2</td>\n",
       "      <td>ptr</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.426502+0.000000j</td>\n",
       "      <td>34.510715</td>\n",
       "      <td>0.874698</td>\n",
       "      <td>0.926181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>HNU1</td>\n",
       "      <td>0025435</td>\n",
       "      <td>10</td>\n",
       "      <td>399</td>\n",
       "      <td>HNU1_0025435_10</td>\n",
       "      <td>raw</td>\n",
       "      <td>combat</td>\n",
       "      <td>0.178570+0.000692j</td>\n",
       "      <td>13.078171</td>\n",
       "      <td>0.996401</td>\n",
       "      <td>0.002714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>HNU1</td>\n",
       "      <td>0025435</td>\n",
       "      <td>10</td>\n",
       "      <td>399</td>\n",
       "      <td>HNU1_0025435_10</td>\n",
       "      <td>ptr</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.425659+0.000000j</td>\n",
       "      <td>34.510715</td>\n",
       "      <td>0.997091</td>\n",
       "      <td>0.003268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>HNU1</td>\n",
       "      <td>0025435</td>\n",
       "      <td>10</td>\n",
       "      <td>399</td>\n",
       "      <td>HNU1_0025435_10</td>\n",
       "      <td>ptr</td>\n",
       "      <td>zscore</td>\n",
       "      <td>0.214425+0.110408j</td>\n",
       "      <td>0.551420</td>\n",
       "      <td>0.956672</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>HNU1</td>\n",
       "      <td>0025435</td>\n",
       "      <td>10</td>\n",
       "      <td>399</td>\n",
       "      <td>HNU1_0025435_10</td>\n",
       "      <td>ptr</td>\n",
       "      <td>ptr</td>\n",
       "      <td>0.427754+0.000000j</td>\n",
       "      <td>34.566747</td>\n",
       "      <td>0.999482</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>HNU1</td>\n",
       "      <td>0025435</td>\n",
       "      <td>10</td>\n",
       "      <td>399</td>\n",
       "      <td>HNU1_0025435_10</td>\n",
       "      <td>ptr</td>\n",
       "      <td>combat</td>\n",
       "      <td>0.425171+0.001273j</td>\n",
       "      <td>34.500136</td>\n",
       "      <td>0.996683</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset  Subject Retest   Ix         Fullname Sxfm    Dxfm  \\\n",
       "0       BNU1  0025880      2    0   BNU1_0025880_2  raw     raw   \n",
       "1       BNU1  0025880      2    0   BNU1_0025880_2  raw  zscore   \n",
       "2       BNU1  0025880      2    0   BNU1_0025880_2  raw     ptr   \n",
       "3       BNU1  0025880      2    0   BNU1_0025880_2  raw  combat   \n",
       "4       BNU1  0025880      2    0   BNU1_0025880_2  ptr     raw   \n",
       "...      ...      ...    ...  ...              ...  ...     ...   \n",
       "3195    HNU1  0025435     10  399  HNU1_0025435_10  raw  combat   \n",
       "3196    HNU1  0025435     10  399  HNU1_0025435_10  ptr     raw   \n",
       "3197    HNU1  0025435     10  399  HNU1_0025435_10  ptr  zscore   \n",
       "3198    HNU1  0025435     10  399  HNU1_0025435_10  ptr     ptr   \n",
       "3199    HNU1  0025435     10  399  HNU1_0025435_10  ptr  combat   \n",
       "\n",
       "              Clustering     Degree  Homophilic  Homotopic  \n",
       "0     0.175662+0.000000j  12.861285    0.874698   0.926181  \n",
       "1     0.127331+0.063867j   0.202158    0.388454   0.803617  \n",
       "2     0.427748+0.000000j  34.424098    0.950291   0.645351  \n",
       "3     0.179922+0.001882j  13.343396    0.892313   0.943219  \n",
       "4     0.426502+0.000000j  34.510715    0.874698   0.926181  \n",
       "...                  ...        ...         ...        ...  \n",
       "3195  0.178570+0.000692j  13.078171    0.996401   0.002714  \n",
       "3196  0.425659+0.000000j  34.510715    0.997091   0.003268  \n",
       "3197  0.214425+0.110408j   0.551420    0.956672   0.000062  \n",
       "3198  0.427754+0.000000j  34.566747    0.999482   0.000037  \n",
       "3199  0.425171+0.001273j  34.500136    0.996683   0.003000  \n",
       "\n",
       "[3200 rows x 11 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batch",
   "language": "python",
   "name": "batch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
